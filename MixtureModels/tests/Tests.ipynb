{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh0TuOJv/iCxIig/g4QtHK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelipeTufaile/MixtureModels/blob/main/MixtureModels/tests/Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 550,
      "metadata": {
        "id": "6xU7j7uVwc_o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.patches import Circle, Arc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_mixture(X, k, random_state):\n",
        "  \"\"\"\n",
        "  Initializes the mixture model with random points as initial means and uniform assingments\n",
        "\n",
        "  Args:\n",
        "      X: (n, d) array holding the data\n",
        "\n",
        "  Returns:\n",
        "      mixture: the initialized gaussian mixture\n",
        "      post: (n, K) array holding the soft counts for all components for all examples\n",
        "  \"\"\"\n",
        "  # Setting seed\n",
        "  np.random.seed(random_state)\n",
        "\n",
        "  # Calculating the number of samples \"n\" in the dataset (X array)\n",
        "  n, d = X.shape\n",
        "\n",
        "  # Initializing the weight (mixing proportions) for each component (cluster)\n",
        "  p = (np.ones(k) / k).reshape(-1,1)\n",
        "\n",
        "  # Initialize the mean array with random points from X as initial means\n",
        "  mu = X[np.random.choice(n, k, replace=False),:]\n",
        "\n",
        "  # Initialize the variance array for each component (cluster)\n",
        "  var = np.array([np.sum((X-mu[j,:])**2, axis=0) for j in range(k)])/(n-1)\n",
        "\n",
        "  return mu, p, var"
      ],
      "metadata": {
        "id": "vYEnMplLUtoq"
      },
      "execution_count": 551,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GaussianProbability(X, mu, var, multivariate_normal=multivariate_normal.pdf):\n",
        "    \"\"\"\n",
        "    The function calculates the probability of X belonging to the Gaussian distribution using the multivariate Gaussian PDF formula.\n",
        "\n",
        "    Args:\n",
        "        X (numpy.ndarray): Point with shape (1, d).\n",
        "        mu (numpy.ndarray): Mean of the Gaussian distribution with shape (1, d).\n",
        "        var (numpy.ndarray): Variance of the Gaussian distribution with shape (1, d).\n",
        "\n",
        "    Returns:\n",
        "        float: Probability of X belonging to the Gaussian distribution.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculating probability\n",
        "    probabilities = multivariate_normal(X, mean=mu, cov=np.diag(var)).T\n",
        "\n",
        "    return probabilities\n"
      ],
      "metadata": {
        "id": "DF7bC-mKVOzo"
      },
      "execution_count": 552,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def estep(X, GMM, GaussianProbability=GaussianProbability):\n",
        "    \"\"\"\n",
        "    E-step: Softly assigns each datapoint to a gaussian component\n",
        "\n",
        "    Args:\n",
        "        X: (n, d) array holding the data mixture: the current gaussian mixture\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: (n, K) array holding the soft counts for all components for all examples\n",
        "        float: log-likelihood of the assignment\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculating the probability for each datapoint [i] belonging to each clusters [j]: probabilities has shape n x j\n",
        "    probabilities = np.array([GaussianProbability(X=X, mu=GMM.mu[j,:], var=GMM.var[j,:]) for j in range(GMM.k)]).T\n",
        "\n",
        "    # Calulating the likelihood for each each datapoint [i] belonging to each clusters [j]: likelihoods has shape n x 1\n",
        "    likelihoods = probabilities@GMM.p\n",
        "\n",
        "    # Calculating the posterior probabilities for each datapoint [i] belonging to each clusters [j]: post has shape n x j\n",
        "    post = ((probabilities.T)*GMM.p).T/likelihoods\n",
        "\n",
        "    # Calculating the sum of log_likelihoods\n",
        "    sum_log_likelihood = np.sum(np.log(likelihoods))\n",
        "\n",
        "    return post, sum_log_likelihood"
      ],
      "metadata": {
        "id": "2EsUl2lbU3DR"
      },
      "execution_count": 553,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mstep(X, post):\n",
        "  \"\"\"\n",
        "  M-step: Updates the gaussian mixture by maximizing the log-likelihood of the weighted dataset\n",
        "\n",
        "  Args:\n",
        "      X: (n, d) array holding the data\n",
        "      post: (n, K) array holding the soft counts for all components for all examples\n",
        "\n",
        "  Returns:\n",
        "      GaussianMixture: the new gaussian mixture\n",
        "  \"\"\"\n",
        "\n",
        "  # Calculating the sum of the posterior probabilities sum_p has shape j x 1\n",
        "  sum_p = np.sum(post, axis=0).reshape(-1,1)\n",
        "\n",
        "  # Updating mixture proportions: p has shape j x 1\n",
        "  p = sum_p/X.shape[0]\n",
        "\n",
        "  # Updating the center of each distribution (cluster)\n",
        "  mu = post.T@X/sum_p\n",
        "\n",
        "  # Updating the variance of each distribution (cluster)\n",
        "  var = np.array([np.sum(post[:,j].reshape(-1,1)*((X-mu[j,:].reshape(1,-1))**2), axis=0) for j in range(post.shape[1])])/(X.shape[1]*sum_p)\n",
        "\n",
        "  return mu, p, var\n"
      ],
      "metadata": {
        "id": "rnmBxu50U6QI"
      },
      "execution_count": 554,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianMixture():\n",
        "  \"\"\"\n",
        "  Tuple holding a gaussian mixture\n",
        "\n",
        "  mu: np.ndarray  # (K, d) array - each row corresponds to a gaussian component mean\n",
        "  var: np.ndarray  # (K, ) array - each row corresponds to the variance of a component\n",
        "  p: np.ndarray  # (K, ) array = each row corresponds to the weight of a component\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "    Initializes the gaussian mixture model.\n",
        "\n",
        "    Args:\n",
        "        K (int): number of components\n",
        "        seed (int): random seed\n",
        "\n",
        "    Returns:\n",
        "        mixture: the initialized gaussian mixture model\n",
        "    \"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      k,\n",
        "      max_iter=10000,\n",
        "      tol=10**(-5),\n",
        "      n_init=1,\n",
        "      verbose=False,\n",
        "      random_state=0\n",
        "    ):\n",
        "\n",
        "    self.k = k\n",
        "    self.max_iter = max_iter\n",
        "    self.tol = tol\n",
        "    self.n_init = n_init\n",
        "    self.verbose = verbose\n",
        "    self.random_state = random_state\n",
        "\n",
        "  def fit(self, X, init_mixture=init_mixture, estep=estep, mstep=mstep):\n",
        "\n",
        "    # Initialize mixture\n",
        "    self.mu, self.p, self.var = init_mixture(X, self.k, self.random_state)\n",
        "\n",
        "    #return self\n",
        "\n",
        "    # Initialize l_theta\n",
        "    l_log_likelihood = []\n",
        "\n",
        "    for i in range(self.max_iter):\n",
        "\n",
        "      # Run E-Step\n",
        "      post, log_likelihood = estep(X=X, GMM=self)\n",
        "\n",
        "      # Run M-Step\n",
        "      self.mu, self.p, self.var = mstep(X=X, post=post)\n",
        "\n",
        "      # Update the list of log_likelihood\n",
        "      l_log_likelihood.append(log_likelihood)\n",
        "\n",
        "    return self, l_log_likelihood\n"
      ],
      "metadata": {
        "id": "p4L5t8lXwmSd"
      },
      "execution_count": 555,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples1 = np.random.normal(np.array([10, 15]), np.array([1, 3]), (1000,2))\n",
        "samples2 = np.random.normal(np.array([50, 70]), np.array([5, 8]), (1000,2))\n",
        "\n",
        "X = np.concatenate([samples1, samples2])\n",
        "\n",
        "# Initializing a Gaussian Mixture Model\n",
        "GMM = GaussianMixture(k=2, max_iter=100, random_state=88)\n",
        "\n",
        "# Fitting the data to the model and finding distributions\n",
        "GMM, l_log_likelihood = GMM.fit(X=X)\n",
        "#GMM = GMM.fit(X=X)\n",
        "\n",
        "# Printing Gaussian Mixture Model parameters\n",
        "for i, params in enumerate(zip(GMM.mu, GMM.var)):\n",
        "  print(f\"Center of distribution {str(i).zfill(3)} is {params[0]} and standard deviation is {params[1]**0.5}\")"
      ],
      "metadata": {
        "id": "BZ4QvDlJTY4T",
        "outputId": "573e5b3b-c0d3-4221-c502-57abc0ef2e22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Center of distribution 000 is [50.04358905 70.29821307] and standard deviation is [3.43401233 5.6785979 ]\n",
            "Center of distribution 001 is [10.01021005 14.91655592] and standard deviation is [0.69425842 2.08572533]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJdR5GsyzhZ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}